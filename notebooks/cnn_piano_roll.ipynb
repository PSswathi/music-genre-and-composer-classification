{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "_26e0326eJ98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "_26e0326eJ98",
        "outputId": "03bff770-d91a-4179-a174-5d0d5c1c6745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/libtpu-tf-releases/index.html\n",
            "Collecting tensorflow-tpu\n",
            "  Downloading tensorflow_tpu-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow-tpu)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow-tpu)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow-tpu)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-tpu)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow-tpu)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow-tpu)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow-tpu)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow-tpu)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-tpu)\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting requests<3,>=2.21.0 (from tensorflow-tpu)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting setuptools (from tensorflow-tpu)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow-tpu)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow-tpu)\n",
            "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow-tpu)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow-tpu)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-tpu)\n",
            "  Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow-tpu)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow-tpu)\n",
            "  Downloading keras-3.11.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-tpu)\n",
            "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow-tpu)\n",
            "  Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-tpu)\n",
            "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting libtpu==2.18.0 (from tensorflow-tpu)\n",
            "  Downloading https://storage.googleapis.com/libtpu-tf-releases/wheels/libtpu-2.18.0-py3-none-any.whl (123.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-tpu)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-tpu)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting rich (from keras>=3.5.0->tensorflow-tpu)\n",
            "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting namex (from keras>=3.5.0->tensorflow-tpu)\n",
            "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
            "Collecting optree (from keras>=3.5.0->tensorflow-tpu)\n",
            "  Downloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-tpu)\n",
            "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow-tpu)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow-tpu)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow-tpu)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-tpu)\n",
            "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-tpu)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-tpu)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-tpu)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-tpu)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.5.0->tensorflow-tpu)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-tpu)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading tensorflow_tpu-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.3/234.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.11.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.0/402.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: namex, libtpu, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, setuptools, pygments, protobuf, packaging, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, optree, ml-dtypes, markdown-it-py, h5py, google-pasta, astunparse, tensorboard, rich, keras, tensorflow-tpu\n",
            "  Attempting uninstall: namex\n",
            "    Found existing installation: namex 0.1.0\n",
            "    Uninstalling namex-0.1.0:\n",
            "      Successfully uninstalled namex-0.1.0\n",
            "  Attempting uninstall: libtpu\n",
            "    Found existing installation: libtpu 0.0.7.1\n",
            "    Uninstalling libtpu-0.0.7.1:\n",
            "      Successfully uninstalled libtpu-0.0.7.1\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.1.0\n",
            "    Uninstalling termcolor-3.1.0:\n",
            "      Successfully uninstalled termcolor-3.1.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.2\n",
            "    Uninstalling Pygments-2.19.2:\n",
            "      Successfully uninstalled Pygments-2.19.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.31.1\n",
            "    Uninstalling protobuf-6.31.1:\n",
            "      Successfully uninstalled protobuf-6.31.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.3.6\n",
            "    Uninstalling Markdown-3.3.6:\n",
            "      Successfully uninstalled Markdown-3.3.6\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.74.0\n",
            "    Uninstalling grpcio-1.74.0:\n",
            "      Successfully uninstalled grpcio-1.74.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.7.14\n",
            "    Uninstalling certifi-2025.7.14:\n",
            "      Successfully uninstalled certifi-2025.7.14\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: optree\n",
            "    Found existing installation: optree 0.17.0\n",
            "    Uninstalling optree-0.17.0:\n",
            "      Successfully uninstalled optree-0.17.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.1\n",
            "    Uninstalling ml_dtypes-0.5.1:\n",
            "      Successfully uninstalled ml_dtypes-0.5.1\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.14.0\n",
            "    Uninstalling h5py-3.14.0:\n",
            "      Successfully uninstalled h5py-3.14.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 14.1.0\n",
            "    Uninstalling rich-14.1.0:\n",
            "      Successfully uninstalled rich-14.1.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "tensorstore 0.1.76 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.8.3 charset_normalizer-3.4.2 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 idna-3.10 keras-3.11.1 libclang-18.1.1 libtpu-2.18.0 markdown-3.8.2 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.1.0 numpy-2.0.2 opt-einsum-3.4.0 optree-0.17.0 packaging-25.0 protobuf-5.29.5 pygments-2.19.2 requests-2.32.4 rich-14.1.0 setuptools-80.9.0 six-1.17.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-tpu-2.18.0 termcolor-3.1.0 typing-extensions-4.14.1 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "google",
                  "numpy",
                  "packaging",
                  "pkg_resources",
                  "six"
                ]
              },
              "id": "0dcf4dd026654a0ab0c601d913a4192e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow-tpu -f https://storage.googleapis.com/libtpu-tf-releases/index.html --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "aldk8JloXmkK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aldk8JloXmkK",
        "outputId": "3d682bb3-92db-41cb-d0c2-428bf557113f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.11/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (2.0.2)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eb201c8e-bd1b-4a4c-8e1e-9b018b55298e",
      "metadata": {
        "id": "eb201c8e-bd1b-4a4c-8e1e-9b018b55298e"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import pretty_midi\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, make_scorer\n",
        "\n",
        "from random import sample\n",
        "from warnings import catch_warnings\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from random import sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Q8KOfmuRcbre",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8KOfmuRcbre",
        "outputId": "09bf289a-2b7f-45d0-bb72-ab5010897a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/jax/__init__.py:31: UserWarning: cloud_tpu_init failed: AttributeError(\"module 'libtpu' has no attribute 'get_library_path'\")\n",
            " This a JAX bug; please report an issue at https://github.com/jax-ml/jax/issues\n",
            "  _warn(f\"cloud_tpu_init failed: {exc!r}\\n This a JAX bug; please report \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "76896531-4411-46b1-9325-a43b30f6e364",
      "metadata": {
        "id": "76896531-4411-46b1-9325-a43b30f6e364"
      },
      "outputs": [],
      "source": [
        "# tensorflow imports\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, layers, utils, callbacks\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dense, Input, Normalization, Flatten, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eYHtGnYOZYGy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYHtGnYOZYGy",
        "outputId": "f77f7d4c-a7e9-4d49-b691-eed9186227b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: \n",
            "Number of replicas: 8\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4sWLlse1u9uU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sWLlse1u9uU",
        "outputId": "4165ffeb-1948-46d2-8cec-b7338f5cbd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a3af77ed-0590-4b78-b77b-be98ad234d22",
      "metadata": {
        "id": "a3af77ed-0590-4b78-b77b-be98ad234d22"
      },
      "outputs": [],
      "source": [
        "# DATA_DIR = \"../selectedcomposers\"\n",
        "\n",
        "# google drive folder\n",
        "DATA_DIR = \"/content/drive/MyDrive/selectedcomposers\"\n",
        "\n",
        "composer_list = [\"Bach\", \"Beethoven\", \"Chopin\", \"Mozart\"]\n",
        "\n",
        "# get all of the files so we can run a concurrent batch to speed up processing\n",
        "file_label_pairs = []\n",
        "for composer in os.listdir(DATA_DIR):\n",
        "    composer_dir = os.path.join(DATA_DIR, composer)\n",
        "    if not os.path.isdir(composer_dir):\n",
        "        continue\n",
        "    for root, _, files in os.walk(composer_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith((\".mid\", \".midi\")):\n",
        "                file_label_pairs.append((os.path.join(root, fn), composer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "150ee22c-1857-458f-8732-27cb0ad6b2b7",
      "metadata": {
        "id": "150ee22c-1857-458f-8732-27cb0ad6b2b7"
      },
      "outputs": [],
      "source": [
        "frequency = 20\n",
        "seq_size = frequency * 10\n",
        "\n",
        "# pad the given sequence with zeros if it is too short\n",
        "def add_padding(seq, x, missing):\n",
        "  right = np.zeros((x, missing))\n",
        "\n",
        "  return np.hstack((seq,right))\n",
        "\n",
        "# get all of the valid sequences from the provided piano roll data.\n",
        "def get_sequences(piano_data):\n",
        "  x, y = piano_data.shape\n",
        "  sequences = []\n",
        "  if(y < seq_size):\n",
        "    sequence = add_padding(piano_data, x, seq_size-y)\n",
        "    sequences.append(sequence)\n",
        "  else:\n",
        "    start = 0\n",
        "    end = 0\n",
        "    while(end < y):\n",
        "      end = start + seq_size\n",
        "      if end > y:\n",
        "        sequence = piano_data[:,start:y]\n",
        "        padded = add_padding(sequence, x, (start + seq_size - y))\n",
        "        sequences.append(padded)\n",
        "      else:\n",
        "        sequence = piano_data[:,start:end]\n",
        "        sequences.append(sequence)\n",
        "      start += 10\n",
        "\n",
        "  return sequences\n",
        "\n",
        "# generate the midi object, remove any invalid notes,\n",
        "# then get the sequences from the piano roll data\n",
        "def get_seq_data(file_path):\n",
        "  midi = pretty_midi.PrettyMIDI(file_path)\n",
        "  midi.remove_invalid_notes()\n",
        "  return get_sequences(midi.get_piano_roll(fs=frequency))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "PrXzkbzqZeTw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrXzkbzqZeTw",
        "outputId": "a4ffbc9b-367e-476d-bd6c-22e0dca70a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "midi_data = []\n",
        "\n",
        "for (path, composer) in file_label_pairs:\n",
        "  midi_data.append({\n",
        "    'composer': composer,\n",
        "    'sequences': get_seq_data(path)\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d87b9acd-85d9-463e-bd06-d5bd3537f576",
      "metadata": {
        "id": "d87b9acd-85d9-463e-bd06-d5bd3537f576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e651a8bd-0598-4f3a-db7c-3cf8f64be3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total shape: (1627, 2)\n",
            "\n",
            "Count by composer:\n",
            "composer\n",
            "Bach         1024\n",
            "Mozart        255\n",
            "Beethoven     212\n",
            "Chopin        136\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "midi_df = pd.DataFrame(midi_data)\n",
        "\n",
        "print(f\"\\nTotal shape: {midi_df.shape}\")\n",
        "print(\"\\nCount by composer:\")\n",
        "print(midi_df['composer'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1f7ae3f9-2928-4534-96ed-2a192df34d6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "1f7ae3f9-2928-4534-96ed-2a192df34d6c",
        "outputId": "2ef6ae88-e793-46ff-d2cd-621a8a91fdc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "composer\n",
              "Bach         298248\n",
              "Beethoven    201956\n",
              "Mozart       199234\n",
              "Chopin        57416\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>composer</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bach</th>\n",
              "      <td>298248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beethoven</th>\n",
              "      <td>201956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mozart</th>\n",
              "      <td>199234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chopin</th>\n",
              "      <td>57416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# get just the sequence data for each composer and the target row\n",
        "seq_data = []\n",
        "for midi in midi_data:\n",
        "    for seq in midi['sequences']:\n",
        "        seq_data.append({\n",
        "            'sequence': np.transpose(seq),\n",
        "            'composer': midi['composer']\n",
        "        })\n",
        "\n",
        "seq_df = pd.DataFrame(seq_data)\n",
        "seq_df['composer'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "rz5hddkwif-g",
      "metadata": {
        "id": "rz5hddkwif-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "4de86219-0616-4206-b686-4298d76ac30c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "composer\n",
              "Bach         15000\n",
              "Beethoven    15000\n",
              "Chopin       15000\n",
              "Mozart       15000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>composer</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bach</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beethoven</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chopin</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mozart</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "rand_sample = 15000\n",
        "sampled_df = seq_df.groupby(\"composer\", group_keys=False).sample(n=rand_sample, random_state=511)\n",
        "sampled_df['composer'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7090480d-3e05-4b98-a4c2-b3eadb6b8ec5",
      "metadata": {
        "id": "7090480d-3e05-4b98-a4c2-b3eadb6b8ec5"
      },
      "outputs": [],
      "source": [
        "X = np.stack(sampled_df['sequence'].values)\n",
        "y = sampled_df['composer'].values\n",
        "\n",
        "# shuffle the dataset with replicable seed\n",
        "indices = np.arange(X.shape[0])\n",
        "np.random.seed(23)\n",
        "np.random.shuffle(indices, )\n",
        "\n",
        "X_shuffled = X[indices]\n",
        "y_shuffled = y[indices]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encode the labels\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y_shuffled.reshape(-1, 1))\n",
        "y = y.toarray()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWB2tbNRr9mG",
        "outputId": "66112831-687f-4801-e7d3-af790396b107"
      },
      "id": "jWB2tbNRr9mG",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c10e6d03-648f-4ce1-a737-f26cd4e5de9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c10e6d03-648f-4ce1-a737-f26cd4e5de9c",
        "outputId": "de1ae6b8-fa00-43ee-dd29-38aa7648e122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train / Val / Test shapes: (48000, 200, 128) (6000, 200, 128) (6000, 200, 128)\n"
          ]
        }
      ],
      "source": [
        "# split into train/test/val\n",
        "TEST_TRAIN_SPLIT = 0.8\n",
        "TEST_VAL_SPLIT = 0.1\n",
        "total = len(X_shuffled)\n",
        "\n",
        "# train, test, and val data\n",
        "X_train = X_shuffled[:int(total * TEST_TRAIN_SPLIT)].copy()\n",
        "y_train = y[:int(total * TEST_TRAIN_SPLIT)].copy()\n",
        "X_test = X_shuffled[int(total * (TEST_TRAIN_SPLIT + TEST_VAL_SPLIT)):].copy()\n",
        "y_test = y[int(total * (TEST_TRAIN_SPLIT + TEST_VAL_SPLIT)):].copy()\n",
        "X_val = X_shuffled[int(total * TEST_TRAIN_SPLIT):int(total * (TEST_TRAIN_SPLIT + TEST_VAL_SPLIT))].copy()\n",
        "y_val = y[int(total * TEST_TRAIN_SPLIT):int(total * (TEST_TRAIN_SPLIT + TEST_VAL_SPLIT))].copy()\n",
        "\n",
        "print(\"Train / Val / Test shapes:\",\n",
        "      X_train.shape, X_val.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the train, test, and val data to an external file.\n",
        "np.savez_compressed(\n",
        "    '../featured datasets/data_splits.npz',\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    X_val=X_val,     y_val=y_val,\n",
        "    X_test=X_test,   y_test=y_test\n",
        ")"
      ],
      "metadata": {
        "id": "-7wGj8Jax1Jh"
      },
      "id": "-7wGj8Jax1Jh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the train, test, and val data and load it in.\n",
        "data = np.load('data_splits.npz')\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_val   = data['X_val']\n",
        "y_val   = data['y_val']\n",
        "X_test  = data['X_test']\n",
        "y_test  = data['y_test']"
      ],
      "metadata": {
        "id": "2N9OOaGD-74J"
      },
      "id": "2N9OOaGD-74J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# global training parameters\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "with strategy.scope():\n",
        "  cnn_model = tf.keras.Sequential([\n",
        "\n",
        "    # tf.keras.layers.Normalization(axis=None),\n",
        "\n",
        "    tf.keras.layers.Conv1D(256, kernel_size=3, activation='relu', padding='causal'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(256, kernel_size=3, activation='relu', padding='causal'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu', padding='causal'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu', padding='causal'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', padding='causal'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', padding='causal'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(len(composer_list), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  cnn_model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['categorical_accuracy', 'precision', 'recall', 'f1_score']\n",
        "  )"
      ],
      "metadata": {
        "id": "WI-vNRxXt0Qx"
      },
      "id": "WI-vNRxXt0Qx",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the callback\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_categorical_accuracy',\n",
        "    patience=5,\n",
        "    mode='max',\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# setup checkpoint\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "  filepath='/content/drive/MyDrive/AAI-511/best_cnn.keras',\n",
        "  monitor='val_categorical_accuracy',\n",
        "  mode='max',\n",
        "  save_best_only=True\n",
        ")\n",
        "\n",
        "history = cnn_model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val,y_val),\n",
        "  epochs=NUM_EPOCHS,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  callbacks=[early_stop, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln8bn1ZjuoQt",
        "outputId": "f7ed2167-6a8e-4fe5-bffa-08d5e6251355"
      },
      "id": "ln8bn1ZjuoQt",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - categorical_accuracy: 0.3634 - f1_score: 0.3500 - loss: 1.3821 - precision: 0.5597 - recall: 0.0934 - val_categorical_accuracy: 0.3662 - val_f1_score: 0.3014 - val_loss: 1.2433 - val_precision: 0.7704 - val_recall: 0.0850\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.5941 - f1_score: 0.5800 - loss: 0.9572 - precision: 0.7148 - recall: 0.3969 - val_categorical_accuracy: 0.5052 - val_f1_score: 0.4644 - val_loss: 1.2066 - val_precision: 0.7183 - val_recall: 0.2668\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.6670 - f1_score: 0.6578 - loss: 0.8215 - precision: 0.7449 - recall: 0.5319 - val_categorical_accuracy: 0.5630 - val_f1_score: 0.5439 - val_loss: 1.0924 - val_precision: 0.6881 - val_recall: 0.3772\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - categorical_accuracy: 0.7054 - f1_score: 0.6992 - loss: 0.7378 - precision: 0.7635 - recall: 0.6131 - val_categorical_accuracy: 0.5547 - val_f1_score: 0.5187 - val_loss: 1.1345 - val_precision: 0.6339 - val_recall: 0.4577\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - categorical_accuracy: 0.7239 - f1_score: 0.7189 - loss: 0.6967 - precision: 0.7734 - recall: 0.6482 - val_categorical_accuracy: 0.6433 - val_f1_score: 0.6358 - val_loss: 0.9041 - val_precision: 0.6847 - val_recall: 0.5370\n",
            "Epoch 6/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.7426 - f1_score: 0.7386 - loss: 0.6530 - precision: 0.7872 - recall: 0.6816 - val_categorical_accuracy: 0.6518 - val_f1_score: 0.6449 - val_loss: 0.9266 - val_precision: 0.7010 - val_recall: 0.5247\n",
            "Epoch 7/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.7548 - f1_score: 0.7511 - loss: 0.6244 - precision: 0.7953 - recall: 0.7021 - val_categorical_accuracy: 0.7033 - val_f1_score: 0.7003 - val_loss: 0.8034 - val_precision: 0.7427 - val_recall: 0.6062\n",
            "Epoch 8/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.7614 - f1_score: 0.7582 - loss: 0.6151 - precision: 0.7988 - recall: 0.7135 - val_categorical_accuracy: 0.6412 - val_f1_score: 0.6228 - val_loss: 0.9404 - val_precision: 0.6704 - val_recall: 0.5432\n",
            "Epoch 9/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - categorical_accuracy: 0.7713 - f1_score: 0.7681 - loss: 0.5907 - precision: 0.8045 - recall: 0.7255 - val_categorical_accuracy: 0.7062 - val_f1_score: 0.7113 - val_loss: 0.8413 - val_precision: 0.7453 - val_recall: 0.6267\n",
            "Epoch 10/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.7779 - f1_score: 0.7750 - loss: 0.5727 - precision: 0.8117 - recall: 0.7321 - val_categorical_accuracy: 0.6853 - val_f1_score: 0.6771 - val_loss: 0.8249 - val_precision: 0.7148 - val_recall: 0.6117\n",
            "Epoch 11/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.7856 - f1_score: 0.7825 - loss: 0.5557 - precision: 0.8197 - recall: 0.7436 - val_categorical_accuracy: 0.7332 - val_f1_score: 0.7306 - val_loss: 0.7368 - val_precision: 0.7706 - val_recall: 0.6398\n",
            "Epoch 12/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.7897 - f1_score: 0.7866 - loss: 0.5534 - precision: 0.8241 - recall: 0.7468 - val_categorical_accuracy: 0.7300 - val_f1_score: 0.7295 - val_loss: 0.7704 - val_precision: 0.7765 - val_recall: 0.6463\n",
            "Epoch 13/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.7967 - f1_score: 0.7940 - loss: 0.5336 - precision: 0.8303 - recall: 0.7545 - val_categorical_accuracy: 0.7675 - val_f1_score: 0.7673 - val_loss: 0.6352 - val_precision: 0.8036 - val_recall: 0.6985\n",
            "Epoch 14/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - categorical_accuracy: 0.8038 - f1_score: 0.8018 - loss: 0.5235 - precision: 0.8371 - recall: 0.7668 - val_categorical_accuracy: 0.7725 - val_f1_score: 0.7741 - val_loss: 0.6713 - val_precision: 0.8086 - val_recall: 0.6793\n",
            "Epoch 15/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.8055 - f1_score: 0.8035 - loss: 0.5174 - precision: 0.8375 - recall: 0.7685 - val_categorical_accuracy: 0.7533 - val_f1_score: 0.7530 - val_loss: 0.6947 - val_precision: 0.7962 - val_recall: 0.6465\n",
            "Epoch 16/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.8091 - f1_score: 0.8069 - loss: 0.5118 - precision: 0.8407 - recall: 0.7731 - val_categorical_accuracy: 0.7665 - val_f1_score: 0.7695 - val_loss: 0.6576 - val_precision: 0.8193 - val_recall: 0.6747\n",
            "Epoch 17/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.8113 - f1_score: 0.8096 - loss: 0.5062 - precision: 0.8438 - recall: 0.7734 - val_categorical_accuracy: 0.7817 - val_f1_score: 0.7834 - val_loss: 0.6421 - val_precision: 0.8291 - val_recall: 0.6735\n",
            "Epoch 18/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.8153 - f1_score: 0.8131 - loss: 0.4998 - precision: 0.8464 - recall: 0.7785 - val_categorical_accuracy: 0.7400 - val_f1_score: 0.7375 - val_loss: 0.7354 - val_precision: 0.7883 - val_recall: 0.6257\n",
            "Epoch 19/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - categorical_accuracy: 0.8192 - f1_score: 0.8173 - loss: 0.4916 - precision: 0.8516 - recall: 0.7819 - val_categorical_accuracy: 0.7470 - val_f1_score: 0.7458 - val_loss: 0.7147 - val_precision: 0.7939 - val_recall: 0.6245\n",
            "Epoch 20/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.8222 - f1_score: 0.8202 - loss: 0.4855 - precision: 0.8538 - recall: 0.7847 - val_categorical_accuracy: 0.7668 - val_f1_score: 0.7651 - val_loss: 0.6729 - val_precision: 0.8169 - val_recall: 0.6802\n",
            "Epoch 21/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.8241 - f1_score: 0.8225 - loss: 0.4818 - precision: 0.8532 - recall: 0.7895 - val_categorical_accuracy: 0.7572 - val_f1_score: 0.7545 - val_loss: 0.7864 - val_precision: 0.8155 - val_recall: 0.5267\n",
            "Epoch 22/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - categorical_accuracy: 0.8184 - f1_score: 0.8166 - loss: 0.4956 - precision: 0.8523 - recall: 0.7771 - val_categorical_accuracy: 0.7535 - val_f1_score: 0.7480 - val_loss: 0.6292 - val_precision: 0.7980 - val_recall: 0.6665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, cat_acc, precision, recall, f1 = cnn_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4bY3-Cv-OZf",
        "outputId": "7677e2eb-516b-45f2-c608-098fc8f3bc26"
      },
      "id": "s4bY3-Cv-OZf",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - categorical_accuracy: 0.7862 - f1_score: 0.7877 - loss: 0.6195 - precision: 0.8376 - recall: 0.6780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Loss: {loss}\\nAccuracy: {cat_acc}\\nPrecision: {precision}\\nRecall: {recall},\\nF1: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIJGJAMa-ZHn",
        "outputId": "e8b8dcdc-1ae0-41bd-8009-33d08721d87c"
      },
      "id": "DIJGJAMa-ZHn",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6194760203361511\n",
            "Accuracy: 0.7861666679382324\n",
            "Precision: 0.8375540375709534\n",
            "Recall: 0.6779999732971191,\n",
            "F1: [0.85863084 0.6921562  0.934495   0.6656626 ]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}